
##### -----Load necessary packages ------

library(dplyr)
library(tidyverse)
library(ggplot2)
###Lemon is used in ggplot2 - facet_rep_grid modification
library(lemon)
#library(data.table)
library(ggthemes)
library(extrafont)
###Routliers is used for outliersmad to find outliers
library(Routliers)

###Make sure I need data.table when I run the code - I don't think I do


##### ----- Load in the data ------

depi_data <-read.table("DEPI_analysis_Seeger.txt", sep = ",", header = FALSE)
head(depi_data)
###add column names
names(depi_data) <- c("individual_plant_metadata", "genotype", "line", "subline", "border", "flat_number", "measurement_ID", "plant_ID", "measurement", "time_point", "measured_value")
###Some time points have an "X" in front of them
###Proportion of time points that have an "X":
sum(str_detect(depi_data$time_point, "X"))/nrow(depi_data)
###Rows that have an "X" in its time point:
depi_X <- depi_data[which(str_detect(depi_data$time_point, "X")),]
head(depi_X)
###Remove these X values
depi_data$time_point <- as.numeric(gsub("X","", depi_data$time_point))
depi_subset <- depi_data%>%filter(!genotype %in% c("b1", "b3", "b1b3", "ftsz2-1", "ftsz2-2", "ftsz-dbl", "Col0" )|(genotype == "Col0"&subline == "1"))
###The December collection period has "growth", while the February collection period has "size"
###Both of these measurements are recording leaf area, so change both to leafarea
levels(depi_subset$measurement)[levels(depi_subset$measurement)=="size"] <- "leafarea"
levels(depi_subset$measurement)[levels(depi_subset$measurement)=="growth"] <- "leafarea"
###Create two data sets based on collection period
###Remove border plants 
feb_data <- filter(depi_subset, substr(plant_ID, 1,4) == "0218", border == FALSE)
dec_data <- filter(depi_subset, substr(plant_ID, 1,4) == "1217", border == FALSE)
###Add a column for day to the Feb data
feb_data <- feb_data%>%mutate(day = case_when(
  between(time_point,0,20) ~ 1,
  between(time_point,20,42)~2,
  between(time_point,42,68)~3,
  between(time_point,68,90)~4,
  between(time_point,90,115)~5,
  between(time_point,115,140)~6,
  between(time_point,140,162)~7,
  between(time_point,162,185)~8,
  between(time_point,185,212)~9,
  between(time_point,212,235)~10,
  between(time_point,235,260)~11,
  between(time_point,260,300)~12
))
###Some npq values are negative
###They should all be positive - shift all values by the lowest npq value (Siobhan is looking into this)
min_npq<-min((filter(feb_data, measurement == "npq"))$measured_value)
feb_data$measured_value[feb_data$measurement == "npq"] <- (feb_data$measured_value[feb_data$measurement == "npq"])+abs(min_npq)

##### ----- Use this to replace outliers with NA ------

###Right now, not necessary because we are using nonparametric analysis
remove_outliers <- feb_data%>%
  group_by(genotype, measurement, time_point)%>%
  mutate(measured_value = replace(measured_value, outliers_mad(measured_value, b=1.4826, threshold=3.5, na.rm=TRUE)$outliers_pos, NA))%>%
  arrange(genotype, measurement, time_point)
###Number of outliers
sum(is.na(remove_outliers$measured_value))
###Proportion of measured values that are outliers
sum(is.na(remove_outliers$measured_value))/nrow(remove_outliers)
###This is a relatively high proportion! Proceed with caution

##### ----- Create a pipeline to find p-value ------

###Initialize an empty data frame
p_value = data.frame()
###For each genotype:
for (i in unique(feb_data$genotype)){
  indiv_data <- feb_data%>% 
    ###Focus on each time point and measurement
    group_by(time_point, measurement)%>%
    ###Create a column with the number of WT individual plants and the number of plants for each genotype
    ###Use this later to calculate effect size
    mutate(n_genotype = length(measured_value[genotype == i]), n_wt = length(measured_value[genotype =="Col0"]))%>%
    ###Create a column of p-values using a nonparametric Wilcox test
    
    ###Default set to exact = TRUE, because our sample sizes are too small to use a normal approximation
    ###But, when there are ties in the values (i.e. one value appears twice in the ranking process), wilcox.test returns to the normal approximation and spits out a warning message
    ###This may be a problem - include correct = FALSE to stop this from happening 
    
    ###More information:
    ###http://courses.atlas.illinois.edu/spring2016/STAT/STAT200/RProgramming/NonParametricStats.html
    ###https://data.library.virginia.edu/the-wilcoxon-rank-sum-test/
    mutate(p = (wilcox.test(measured_value[genotype == i], measured_value[genotype == "Col0"], correct = FALSE))$p.value)%>%
    
    ###Add a column with each genotype
    mutate(genotype = i)%>%
    
    select(time_point, genotype, measurement, day, p, n_wt, n_genotype)

    
  ###Add individual information to the main data frame
  p_value = rbind(as.data.frame(indiv_data), p_value)}

###Verify that this pipeline gives the correct p-values by randomly choosing genotype/measurement/time point
###Find each p-value through the pipeline and through filtering and computing the test
###Test 1 
filter(p_value, genotype == "mpk1", time_point == "1", measurement == "npq")$p
a <- filter(feb_data, genotype == "mpk1", time_point == "1", measurement == "npq")$measured_value
b <- filter(feb_data, genotype == "Col0", time_point == "1", measurement == "npq")$measured_value
wilcox.test(a, b, correct = FALSE)$p.value
###Test 2
filter(p_value, genotype == "mpk14-17", time_point == "266.9997", measurement == "leafarea")$p
c <- filter(feb_data, genotype == "mpk14-17", time_point == "266.9997", measurement == "leafarea")$measured_value
d <- filter(feb_data, genotype == "Col0", time_point == "266.9997", measurement == "leafarea")$measured_value
wilcox.test(c,d, correct = FALSE)$p.value
###Test 3
filter(p_value, genotype == "mpk13", time_point == "38.0003", measurement == "phi2")$p
e <- filter(feb_data, genotype == "mpk13", time_point == "38.0003", measurement == "phi2")$measured_value
f <- filter(feb_data, genotype == "Col0", time_point == "38.0003", measurement == "phi2")$measured_value
wilcox.test(e,f, correct = FALSE)$p.value

###Now, adjust the p-values using an FDR correction
p_value <- p_value%>%
  ###For some reason, I have multiple copies of each row
  distinct()%>%
  ###Group by time point and measurement - we are correcting by the number of genotypes 
  group_by(time_point, measurement)%>%
  mutate(p_adj = p.adjust(p, method = "fdr"))%>%
  ###Effect size calculated using method from:
  ###https://stats.stackexchange.com/questions/133077/effect-size-to-wilcoxon-signed-rank-test
  
  ###Only report an effect size if the p-value is significant; otherwise, NA
  mutate(effect = ifelse(p < 0.05, (abs(qnorm(p_adj))/sqrt(n_wt+n_genotype)), NA))%>%
  mutate(effect_size = case_when(
    ###Make sure these are the right cut offs for magnitude of effect size
    (effect <0.1)~"small",
    (effect>0.1 & effect < 0.5)~"medium",
    (effect>0.5)~"large"))

###Gather the data to make it easier to plot according to whether p was adjusted
p_value <- gather(p_value, type, p, p, p_adj)%>%arrange(genotype, time_point)

###Notice that some effect sizes are infinite
###This applies to p-values of 1; qnorm(1) = infinity
p_value[(which(p_value$effect==Inf)),]
###Need to look into this, because the adjusted p value is very different from the initial p value


###Next, plot the p-values seperated by the adjusted and initial values
ggplot(p_value, aes(x=p, color=type)) +
  geom_histogram(fill="white", alpha=1, position="identity", size = 2)+
  
  ###Include a vertical line with the significant p-value alpha = 0.05
  geom_text(aes(x = 0.18, label = "p=0.05", y =  3000), color = "red", size = 8)+
  geom_vline(xintercept=0.05, color = "red", size = 1.5)+
  
  theme_igray(base_family = "Calibri",
              base_size = 20)+
  labs(title = "P-Value with FDR Correction")


###Here, get counts for p-values, grouped by whether they were adjusted or not
p_value%>%group_by(type)%>%summarize(p_lessthan_0.05 = sum(p<0.05), p_0.05_0.1 = sum(0.05<p & p<0.1), p_0.1_0.2 = sum(0.1<p & p<0.2))
###Notice that adjustment makes many significant p-values insignificant

###Summary statistics for the p values for each measurement
###Notice that leaf area is never significant
p_value%>%filter(type == "p_adj")%>%group_by(measurement)%>%summarize(median = median(p), min = min(p), max = max(p))


##### ----- P-value visualizations ------


###Create seperate data frames for each measurement to use in plots
###Only use the adjusted p-value
npq_p <- filter(p_value, measurement == "npq", type == "p_adj")%>%
  ###Create a new column with the p-value "bins"
  mutate(bin = case_when(
    (p <0.01)~ 'p<0.01',
    (p>0.01 & p < 0.05)~ "0.01<p<0.05",
    (p>0.05)~"p>0.05"))
phi2_p <- filter(p_value, measurement == "phi2", type == "p_adj")%>%
  mutate(bin = case_when(
    (p <0.01)~ 'p<0.01',
    (p>0.01 & p < 0.05)~ "0.01<p<0.05",
    (p>0.05)~"p>0.05"))
leafarea_p <- filter(p_value, measurement == "leafarea", type == "p_adj")%>%
  mutate(bin = case_when(
    ###The minimum p-value for leaf area is 0.304, so adjust the bins:
    (p <0.4)~ 'p<0.4',
    (p>0.4 & p < 0.6)~ "0.4<p<0.6",
    (p>0.6)~"p>0.6"))


###In order to use these bins as the fill in a heat map, convert to a factor
npq_p$bin <- as.factor(npq_p$bin)
###We want p<0.1 to be first in the legend, so refactor with p<0.01 as the first term
npq_p$bin <- relevel(npq_p$bin, 'p<0.01')

phi2_p$bin <- as.factor(phi2_p$bin)
phi2_p$bin <- relevel(phi2_p$bin, 'p<0.01')

leafarea_p$bin <- as.factor(leafarea_p $bin)
leafarea_p$bin <- relevel(leafarea_p $bin, 'p<0.4')

###Create a heat map of p-values for each measurement:
### x is time point
### y is genotype
### fill is p-value with FDR correction

##### ----- P-value heat map - NPQ ------

ggplot(data = npq_p, aes(x = time_point, y = genotype, fill = bin)) + 
  labs(fill = "P-Value, \n with FDR Correction", x = "Hours", y = NULL, title = "P-Value for NPQ using a Wilcox Test")+
  geom_tile(width = 10 , height = 20)+
  facet_grid(genotype ~ day, scales = "free", switch = "y")+
  scale_x_continuous(breaks = round(c(0,15,24,39.5,48,63.7,72,87,96,112,120,135,144,159,168,183,192,207,216,231,240,255,264,279),0))+
  theme_tufte(base_family = "Calibri",
              base_size = 20)+
  theme(strip.background.y = element_blank(),
        strip.text.y = element_blank(),
        panel.spacing=unit(0, "lines"))+
  scale_fill_manual(values = c("red", "orange", "black"))

##### ----- P-value heat map - leaf area ------

###This plot doesn't really tell us anything, because nothing is significantly different from wildtype
ggplot(data = leafarea_p, aes(x = time_point, y = genotype, fill = bin)) + 
  labs(fill = "P-Value, \n with FDR Correction", x = "Hours", y = NULL, title = "P-Value for Leaf Area using a Wilcox Test")+
  geom_tile(width = 10 , height = 20)+
  facet_grid(genotype ~ day, scales = "free", switch = "y")+
  scale_x_continuous(breaks = round(c(0,15,24,39.5,48,63.7,72,87,96,112,120,135,144,159,168,183,192,207,216,231,240,255,264,279),0))+
  theme_tufte(base_family = "Calibri",
              base_size = 20)+
  theme(strip.background.y = element_blank(),
        strip.text.y = element_blank(),
        panel.spacing=unit(0, "lines"))+
  scale_fill_manual(values = c("red", "orange", "black"))

##### ----- P-value heat map - phi2 ------

ggplot(data = phi2_p, aes(x = time_point, y = genotype, fill = bin)) + 
  labs(fill = "P-Value, \n with FDR Correction", x = "Hours", y = NULL, title = "P-Value for Phi2 using a Wilcox Test")+
  geom_tile(width = 10 , height = 20)+
  facet_grid(genotype ~ day, scales = "free", switch = "y")+
  scale_x_continuous(breaks = round(c(0,15,24,39.5,48,63.7,72,87,96,112,120,135,144,159,168,183,192,207,216,231,240,255,264,279),0))+
  theme_tufte(base_family = "Calibri",
              base_size = 20)+
  theme(strip.background.y = element_blank(),
        strip.text.y = element_blank(),
        panel.spacing=unit(0, "lines"))+
  scale_fill_manual(values = c("red", "orange", "black"))

##### ----- Create a for loop to visualize p-values for each combination of single and double mutants ------


genotype_combinations <- list(c("mpk1-17", "mpk1", "mpk17"), c("mpk1-16", "mpk1", "mpk16"), c("mpk6-9", "mpk6", "mpk9"),
                              c("mpk17-20","mpk17", "mpk20"), c("mpk14-17", "mpk14", "mpk17"), c("mpk8-17", "mpk8","mpk17"),
                              c("mpk8-20","mpk8","mpk20"), c("mpk6-18", "mpk6", "mpk18"), c("mpk1-13", "mpk1", "mpk13"), c("mpk17-20", "mpk17", "mpk20"), c("mpk13-20", "mpk13", "mpk20"), c("mpk6-8", "mpk6", "mpk8"), c("mpk9-18", "mpk9", "mpk18"),
                              c("mpk6-20", "mpk6", "mpk20"), c("mpk14-16", "mpk14", "mpk16"), c("mpk18-20", "mpk18", "mpk20"), c("mpk5-6", "mpk5", "mpk6"), c("mpk14-18", "mpk14", "mpk18"), c("mpk5-6", "mpk5", "mpk6"), c("mpk14-18", "mpk14", "mpk18"), c("mpk5-17", "mpk5", "mpk17"),
                              c("mpk1-3", "mpk1", "mpk3"), c("mpk1-17", "mpk1", "mpk17"), c("mpk3-16", "mpk3", "mpk16"), c("mpk9-16", "mpk9", "mpk16"), c("mpk14-20", "mpk14", "mpk20"))

###Values below the red line are significant
###"Unorthodox" way of visualizing p-values, but still interesting to see how they change over time
for (element in genotype_combinations){
  data <- filter(p_value, genotype %in% element)
  plot <- ggplot(data = data, aes(x = time_point, y = p))+
    geom_line(aes(color = genotype), size = 1)+
    facet_rep_grid(measurement ~ day, scales = "free" , switch = "y", repeat.tick.labels = FALSE)+
    labs(x = "Hours", y = NULL)+
    theme_tufte(base_family = "Calibri",
                base_size = 18)+
    theme(strip.background.x = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 1),
          axis.line=element_line(),
          panel.spacing = unit(1, "lines"))+
    scale_x_continuous(breaks = round(c(0,15,24,39.5,48,63.7,72,87,96,112,120,135,144,159,168,183,192,207,216,231,240,255,264,279),0))+
    scale_color_viridis_d(begin = 0, end = 1, option = 'viridis', aesthetics = c("colour", "fill"))+
    geom_hline(yintercept=0.05, color = "red", size = 1.5)
  print(plot)
}

##### ----- Effect sizes ------

###Make the effect sizes factors, so we can create levels and the x-axis will be sorted correctly in ggplot2
p_value$effect_size <- factor(p_value$effect_size, levels = c("small", "medium", "large"))

###Distribution of effect sizes:
ggplot(data = subset(p_value, !is.na(effect_size)), aes(x = effect_size, na.rm = TRUE))+
  geom_bar()

