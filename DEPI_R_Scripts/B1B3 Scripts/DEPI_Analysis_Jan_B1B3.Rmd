---
title: "DEPI Analysis - January B1B3"
author: "Abigail Seeger"
date: "July 7, 2020"
output:
  pdf_document:
    toc: yes
    toc_depth: '4'
    fig_height: 25
    fig_width: 25
  html_document:
    fig_height: 25
    fig_width: 25
    highlight: tango
    number_sections: yes
    theme: paper
    toc: yes
    toc_collapsed: yes
    toc_depth: 4
    toc_float: yes

---

```{r include =FALSE}
library(knitr)
library(formatR)

knitr::opts_chunk$set(message=FALSE, echo = TRUE, warning = FALSE, dev = "cairo_pdf",
tidy.opts=list(width.cutoff=40),tidy=TRUE, cache = TRUE) 

```

This is the analysis of Arabadopsis plants grown in the DEPI chambers (Dynamic Enivronmental Photosynthetic Imager) at Michigan State University. The plants are a range of B1B3 mutants. The purpose of this experiment is to investigate the degree of redundancy in this gene family. 

This data was collected in January 2018. Additional collection periods include December 2017, February 2018, and March 2018.

We will analyze each collection period seperately. This is the analysis for the January experiment for the B1B3 family. There are additional files for MPK and Ftsz analysis. 

#All Data 
##Load and clean data

To begin, load necessary packages:

```{r message = FALSE}
library(dplyr)
library(tidyverse)
library(ggplot2)
###Lemon is used in ggplot2 - facet_rep_grid modification
library(lemon)
library(data.table)
library(ggthemes)
library(extrafont)
###Routliers is used for outliersmad to find outliers
library(Routliers)
library(stringi)
library(viridis)
```

Next, load in the data. This data includes all gene families - we will later filter to only select Col0, B1B3, B1, and B3 genotypes. This data is in a seperate query from the December and February data. I included all columns in both the individual_plant_metadata and the DEPI measurement files - for the other experiments, I did not include all of these columns. 

```{r load_depi_data}
###Read in the January Data - this excludes growth, days 1 through 7
depi_data <- read.table("C:/Users/Owner/Documents/Research/Shiu_Lab/Shiu_Lab_R/Data/Correct_January_Created_Jan132021.csv", sep = ",", header = TRUE, stringsAsFactors = FALSE)
###Add column names to depi_jan
names(depi_data) <- c("measurement_ID", "plant_ID", "DEPI_ID", "time_point", "measured_value", "light_regimen", "measurement", "individual_plant_metadata", "genotype", "line", "subline", "full_subline_information", "experiment_number", "flat_number","cell_number", "row_number", "column_number", "border", "treatment")
###Read in the separate data frame with January growth days 1 through 7
depi_jan_growth <- read.table("C:/Users/Owner/Documents/Research/Shiu_Lab/Shiu_Lab_R/Data/Jan_Growth_Days_1_7.txt", sep = ",", header = TRUE, stringsAsFactors = FALSE)
###Add column names to depi_jan_growth
names(depi_jan_growth) <- c("individual_plant_metadata", "genotype", "line", "subline", "full_subline_information", "experiment_number", "flat_number", "cell_number", "row_number", "column_number", "border", "treatment", "measurement_ID", "plant_ID","DEPI_ID", "time_point", "measured_value", "light_regimen", "measurement")
depi_data <- rbind(depi_jan_growth, depi_data)
```



We only want to analyze the B1B3 genes in this analysis. And, we only want subline 1 of Col0.

Note that I initially included all sublines of Col0 because of a mistake in the following code:

depi_data%>%filter(genotype %in% c("b1", "b3", "b1b3", **"Col0"**)|(genotype == "Col0"&subline == "1"))

I corrected the mistake here. 

```{r create_b1b3_subset}
jan_b1b3 <- depi_data%>%filter(genotype %in% c("b1", "b3", "b1b3" )|(genotype =="Col0" & full_subline_information %in% c("Col1_1", "Col1_3", "Col1_4", "Col1_2")))

unique(filter(jan_b1b3, genotype =="Col0")$full_subline_information)
```

Next, to stay consistent with the December and February data sets, rename growth to leaf area. 

```{r convert_growth_size_leafarea}
###Growth is recording leaf area, so change to leafarea
levels(jan_b1b3$measurement)[levels(jan_b1b3$measurement)=="growth"] <- "leafarea"
```

There is no need to make subsets for experiment - this data set is only January. But, still remove the border plants. 

```{r create_feb_dec_subsets}
###Create two data sets based on collection period and remove border plants 
jan_b1b3 <- filter(jan_b1b3, border == FALSE)
```

Finally, lets look at the genotypes we have in this subset:

```{r genotype_invest}
unique(jan_b1b3$genotype)
```

This confirms that we have selected the genotypes we want.

As a note, I expect this analysis to take much shorter to run than the data set containing all mpk genotypes. 

##Create functions

These functions will be applied to each experiment (December, January, and February) and each gene family (mpk, ftsz, B1B3) seperately.

###add_day_col

The add_day_col function adds a column with the day of the experiment to the data frame. This function first looks for breaks in the data - data was only collected when the lights were on, so a break of greater than five hours indicates a change of day. Then, a number is assigned to indicate the day of the experiment. 

This is a different function than a previous approach I was taking. A previous function found breaks in the data, under the assumption that each experiment would have periods of no collection during the night.

This code is simpler and easy to understand. 


```{r add_day_col}
add_day_col <- function(df){
  
    df$time_point <- as.integer(df$time_point)

    out <- df%>%
    mutate(day = case_when(
    (df$time_point < 24)~ '1',
    (df$time_point >= 24 & df$time_point < 48)~ '2',
    (df$time_point >= 48 & df$time_point < 72)~ '3',
    (df$time_point >= 72 & df$time_point < 96)~ '4',
    (df$time_point >= 96 & df$time_point < 120)~ '5',
    (df$time_point >= 120 & df$time_point < 144)~ '6',
    (df$time_point >= 144 & df$time_point < 168)~ '7',
    (df$time_point >= 168 & df$time_point < 192)~ '8',
    (df$time_point >= 192 & df$time_point < 216)~ '9',
    (df$time_point >= 216 & df$time_point < 240)~ '10',
    (df$time_point >= 240 & df$time_point < 264)~ '11',
    (df$time_point >= 264 & df$time_point < 288)~ '12',
    (df$time_point >= 288 & df$time_point < 312)~ '13',
    (df$time_point >= 312 & df$time_point < 336)~ '14',
    (df$time_point >= 336 & df$time_point < 360)~ '15'
    ))
    out$day <- as.integer(out$day)
    return(out)}

```

###remove_outliers

The remove_outliers function replaces measured values that are outliers with NA. Because we will analyze the data using nonparametric analysis, this function will not be applied to the data, because outliers have little influence on the median value. 

First, group by genotype, measurement type, and time point. Once we've focused in on this, conduct the outliers_mad test using a conservative threshold value of 3.5. If the outliers_mad function finds an outlier, use the position of the outlier to replace the measured value with NA. 

```{r remove_outliers}
remove_outliers<- function(df){
  out <- df%>%
  group_by(genotype, measurement, time_point)%>%
  mutate(measured_value = replace(measured_value, outliers_mad(measured_value, b=1.4826, threshold=3.5, na.rm=TRUE)$outliers_pos, NA))%>%
  arrange(genotype, measurement, time_point)
  return(out)}
```

###p_value

The p_value function finds the p-value for the comparison of each genotype to wildtype in order to answer the question - does the phenotype (either leaf area, npq, or phi2) significantly differ from wild type? The test is repeated for each time point for each genotype.

More information on the specifics used in the Wilcox test can be found [here](http://courses.atlas.illinois.edu/spring2016/STAT/STAT200/RProgramming/NonParametricStats.html) and [here](https://data.library.virginia.edu/the-wilcoxon-rank-sum-test/).

The function is heavily commented, explaining each step in the pipeline. 

```{r p_value}
p_value <- function (data_frame){
  ###Initialize an empty data frame
  out = data.frame()
  ###For each genotype:
  for (i in unique(filter(data_frame, genotype != "Col0")$genotype)){
    ###We don't want to make comparisons of WT to itself - this could impact FDR correction
    indiv_data <- data_frame%>% 
      ###Focus on each time point and measurement
      group_by(time_point, measurement)%>%
      ###Create a column with the number of WT individual plants and the number of plants for each genotype
      ###Use this later to calculate effect size
      mutate(n_genotype = length(measured_value[genotype == i]), n_wt = length(measured_value[genotype =="Col0"]))%>%
      ###Create a column of p-values using a nonparametric Wilcox test
      
      ###Default set to exact = TRUE, because our sample sizes are too small to use a normal approximation
      ###But, when there are ties in the values (i.e. one value appears twice in the ranking process), wilcox.test returns to the normal approximation and spits out a warning message
      ###This may be a problem - include correct = FALSE to stop this from happening 

      ###Paired = FALSE, because the Col0 plants are independet from each genotype
      ###Correct = FALSE turns off the continuity correction
      mutate(p = (wilcox.test(measured_value[genotype == i], measured_value[genotype == "Col0"], correct = FALSE, paired = FALSE))$p.value)%>%
  
      ###Add a column with each genotype
      mutate(genotype = i)%>%
      # mutate(number = unique(filter(feb_data, genotype == i)$number))%>%
      # mutate(number_2 = unique(filter(feb_data, genotype == i)$number_2))%>%
      # 
      select(time_point, genotype, measurement, day, p, n_wt, n_genotype)
  
      
    ###Add individual information to the main data frame
    out <- rbind(as.data.frame(indiv_data), out)}
  return(out)}
```

###corrected_p_value

The corrected_p_value function corrects the p-values using an FDR correction. First, the data is grouped by measurement and time point. Then, the p-value are corrected by the number of genotypes. [This function also computes effect size.](https://stats.stackexchange.com/questions/133077/effect-size-to-wilcoxon-signed-rank-test)

https://stats.stackexchange.com/questions/133077/effect-size-to-wilcoxon-signed-rank-test
  
Once again, the function is heavily commented, explaining each step of the pipeline.

```{r corrected_p_value}
corrected_p_value <- function(data_frame){
  out <- data_frame%>%
  ###For some reason, I have multiple copies of each row
  distinct()%>%
  ###Group by time point and measurement - we are correcting by the number of genotypes 
  group_by(time_point, measurement)%>%
  mutate(p_adj = p.adjust(p, method = "fdr"))%>%
  ###Only report an effect size if the p-value is significant; otherwise, NA
  mutate(effect = ifelse(p < 0.05, (abs(qnorm(p_adj))/sqrt(n_wt+n_genotype)), NA))%>%
  mutate(effect_size = case_when(
    ###Make sure these are the right cut offs for magnitude of effect size
    (effect <0.1)~"small",
    (effect>0.1 & effect < 0.5)~"medium",
    (effect>0.5)~"large"))
  ###Gather the data to make it easier to plot according to whether p was adjusted
  out <- gather(out, type, p, p, p_adj)%>%arrange(genotype, time_point)
  return(out) 
}

```

###add_number

The add_number function adds two columns - number and number_2. number is used to sort the heat maps that include all genotypes, while number_2 is used to sort the heat maps that are a trio of double and single mutants. 

The code is not intuitive - it is commented throughout to explain each step. 

This function differs slightly from the add_number function for the MPK genotypes. This is because there are no "-" in the genotypes for the B1B3 gene family, and a number can easily be assigned based off the number of characters in the genotype. 

```{r add_number}
add_number <- function(data_frame){
  ###First, if the genotype is Col0 (only genotype with length 4), assign 0 as number
  ###Else, assign number as genotype with "mpk" removed
  ###Example: mpk1 will be 1, mpk1-17 will be 1-17
  data_frame <- data_frame%>%
    mutate(number = ifelse(genotype != "Col0",nchar(as.character(genotype)), 0))
  
  data_frame <- data_frame%>%
    mutate(number_2 = number)
  
  data_frame$number_2[data_frame$number_2 == 4] <- 0
  return(data_frame)
}
```

###cell_370_data

The cell_370_data function prepares the data to use in visualizations mirrored after page 370 of the Cell paper Dynamic Environmental Photosynthetic Imaging Reveals Emergent Phenotypes.

This function groups the data by genotype, and for each time point and each measurement finds the median measured value of the plants. Because of how variable the leaf area measurements are between time points, only the beginning and end of each day will be plotted. 


```{r cell_370_data_function}
cell_370_data <- function(data_frame){
  npq_phi2 <- data_frame%>%
     filter(measurement %in% c("npq","phi2"))%>%
     group_by(genotype, time_point, measurement)%>%
     summarize(med = median(measured_value))
  ###For each day, we want the minimum and maximum time point for leaf area
  
  ###Previously included the midpoint - leave code in case we want to use in the future, just commented out
  
  ###If there are an odd number of time points, use the median time point
  ###If there are an even number of time points, instead of finding the average of the two center values, choose the larger value
  #start_mid_end <- unique((data_frame%>%group_by(day)%>%filter(time_point %in% c(min(time_point), max(time_point), ifelse(length(time_point %% 2 == 0), median(time_point[-1]), median(time_point)))))$time_point)
  
  start_end <- unique((data_frame%>%group_by(day)%>%filter(time_point %in% c(min(time_point), max(time_point))))$time_point)
  
  leaf_area <- data_frame%>%
    filter(measurement == "leafarea")%>%
    filter(time_point %in% start_end)%>%
    group_by(genotype, time_point, measurement)%>%
    summarize(med = median(measured_value))
  
  out <- rbind(npq_phi2, leaf_area)%>%group_by(genotype, time_point, measurement)
  
  return(as.data.frame(out))}
```

###cell_371_data

The cell_371_data_function prepares the data to use to create visualizations mirrored after page 371 in the Cell paper Dynamic Environmental Photosynthetic Imaging Reveals Emergent Phenotypes.

This function:

* groups the data by time point and measurement and genotype
* divides the measured value of each genotype by the median wild type value
* calculates the log 2 value for the median of these values

Similar to above, we are only interested in the start and end time points for the leaf area measurement. 

```{r cell_371_data_function}
cell_371_data <- function (data_frame) {
  
  npq_phi2 <- data_frame%>%
    filter(measurement %in% c("npq","phi2"))%>%
    group_by(time_point, measurement)%>%
    mutate_each(funs(./median(.[genotype == "Col0"])), measured_value)%>%
    group_by(time_point, measurement, genotype)%>%
    mutate(log2_fold = log2(median(measured_value)))
  
  #start_mid_end <- unique((data_frame%>%group_by(day)%>%filter(time_point %in% c(min(time_point), max(time_point), ifelse(length(time_point %% 2 == 0), median(time_point[-1]), median(time_point)))))$time_point)
  start_end <- unique((data_frame%>%group_by(day)%>%filter(time_point %in% c(min(time_point), max(time_point))))$time_point)
  
  leaf_area <- data_frame%>%
    filter(measurement == "leafarea")%>%
    filter(time_point %in% start_end)%>%
    group_by(time_point, measurement)%>%
    mutate_each(funs(./median(.[genotype == "Col0"])), measured_value)%>%
    group_by(time_point, measurement, genotype)%>%
    mutate(log2_fold = log2(median(measured_value)))
  
  out <- rbind(npq_phi2, leaf_area)%>%group_by(genotype, time_point, measurement)
  
  return(as.data.frame(out))
}

```

###Genotype combinations

Finally, define a list of all combinations of single and double mutants. We will use this multiple times in the following analysis to loop through each combination to create plots.

This may be unnecessary for this small subset, but leave in to keep analysis consistant to mpk analysis. 

```{r}
genotype_combinations_b1b3 <- list(c("b1b3", "b1", "b3"))
```

#B1B3 Analysis
##Further Cleaning

Here is a summary of the measured values.
```{r jan_b1b3_summary_measured_value}
jan_b1b3%>%group_by(measurement)%>%summarize(min = min(measured_value))
```

The minimum value for npq is negative. We need to shift all npq values by the minimum value, so that the new minimum value is 0.

```{r jan_b1b3_shift_npq}
jan_b1b3$measured_value[jan_b1b3$measurement == "npq"] <- (jan_b1b3$measured_value[jan_b1b3$measurement == "npq"])+abs(min((filter(jan_b1b3, measurement == "npq"))$measured_value))

```

Confirm that the new minimum value is 0:

```{r jan_b1b3_summary_measured_value_confirm}
jan_b1b3%>%group_by(measurement)%>%summarize(min = min(measured_value))
```

Next, add a column with the day to the data, and columns with number and number_2 that we will use later to sort visualizations. 

```{r jan_b1b3_apply_functions}
jan_b1b3 <- add_day_col(add_number(jan_b1b3))
```

Even though we won't remove outliers from the data set, we still want to see how many of our measured values would be considered outliers. 

```{r jan_b1b3_outliers}
jan_b1b3_outliers <- remove_outliers(jan_b1b3)
###Number of outliers
sum(is.na(jan_b1b3_outliers$measured_value))
###Proportion of measured values that are outliers
sum(is.na(jan_b1b3_outliers$measured_value))/nrow(jan_b1b3_outliers)

```


## P-Values

Next, apply the p_value function to the data, and make sure that the function is working properly by completing a few random tests of the data. 

```{r  message = FALSE, warning = FALSE}
jan_b1b3_p <- p_value(jan_b1b3)

###Test 1 
unique(filter(jan_b1b3_p, genotype == "b1", time_point == "1", measurement == "npq")$p)
a <- filter(jan_b1b3, genotype == "b1", time_point == "1", measurement == "npq")$measured_value
b <- filter(jan_b1b3, genotype == "Col0", time_point == "1", measurement == "npq")$measured_value
wilcox.test(a, b, correct = FALSE)$p.value
###Test 2
unique(filter(jan_b1b3_p, genotype == "b1b3", time_point == "0", measurement == "leafarea")$p)
c <- filter(jan_b1b3, genotype == "b1b3", time_point == "0", measurement == "leafarea")$measured_value
d <- filter(jan_b1b3, genotype == "Col0", time_point == "0", measurement == "leafarea")$measured_value
wilcox.test(c,d, correct = FALSE)$p.value

```

Now, correct the p-values using an FDR correction. Also, convert the effect sizes to a factor so we can create levels and sort subsequent plots properly. 

```{r jan_b1b3_correct_p_values}
jan_b1b3_p_corrected <- corrected_p_value(jan_b1b3_p)
jan_b1b3_p_corrected$effect_size <- factor(jan_b1b3_p_corrected$effect_size, levels = c("small", "medium", "large"))
summary(jan_b1b3_p_corrected$effect_size)
```

Here is the distribution of the effect sizes - note that there are no "small" effect sizes.


```{r jan_b1b3_investigate_effect}
ggplot(data = subset(jan_b1b3_p_corrected, !is.na(effect_size)), aes(x = effect_size, na.rm = TRUE))+
  geom_bar()+
  labs(x = "Effect size", y = "Count", title = "January: Effect size for significant p-values, for B1B3")+
  theme_minimal(base_family = "Calibri",
              base_size = 50
              )
#ggsave("jan_b1b3_effect_size.png", scale = 4)
```

Next, look at summary statistics for the p-values:

```{r jan_b1b3_summary_p}
###Summary statistics for the p values for each measurement;leaf area is never significant
jan_b1b3_p_corrected%>%group_by(measurement, type)%>%summarize(median = median(p), min = min(p), max = max(p))
###Here, get counts for p-values, grouped by whether they were adjusted or not; notice that adjustment makes many significant p-values insignificant
jan_b1b3_p_corrected%>%group_by(type)%>%summarize(p_lessthan_0.05 = sum(p<0.05), p_lessthan_0.01 = sum(p<0.01))

```

**Note that we will note include any heat maps of the p-values for npq, because the minimum p-value is above 0.05**

Next, we will visualize p-values for January for B1B3. Create a modified data frame to be used in to create visualizations.

```{r jan_b1b3_create_plot_data}
###Add columns with number and number_2 - we will use these the sort the plots
jan_b1b3_plot <- add_number(jan_b1b3_p_corrected)

jan_b1b3_plot <- jan_b1b3_plot%>%arrange(day)
```

First, investigate the distribution of corrected and uncorrected p-values for all measurements.

```{r jan_b1b3_p_dist}
###Plot the p-values seperated by the adjusted and initial values
ggplot(jan_b1b3_plot, aes(x=p, color=type)) +
  geom_histogram(position="stack", fill = "white", size = 2)+
  scale_color_viridis(discrete = TRUE, option = "E")+
  facet_grid(~measurement)+
  ###Include a vertical line with the significant p-value alpha = 0.05
  geom_text(aes(x = 0.18, label = "p=0.05", y =  150), color = "black", size = 20)+
  geom_vline(xintercept=0.05, color = "black", size = 1)+
  theme_minimal(base_family = "Calibri",
              base_size = 50)+
  labs(x = "P-Value", y = "Count", title = "January: P-value Distribution, for B1B3")

#ggsave("jan_b1b3_adjusted_unadjusted_p_values.png", scale = 4)
```

### Uncorrected p-value heat maps

Next, create subsets of the data based on measurement. We want to plot the p-values for phi2, npq, and leaf area seperately.

Add bins for the p-values to easily visualize what is significant and what isn't. The minimum p-value for leafarea is greater than 0.05. For this experiment, leaf area is significantly different for both the p and adjusted p values - this was not the case for the December and February experiments.  

This does not apply to the npq measurement, because no p-values are significant. 


```{r jan_b1b3_plot_subsets}
###Create seperate data frames for each measurement to use in heat maps; don't use adjusted p-values
jan_b1b3_phi2 <- filter(jan_b1b3_plot, measurement == "phi2", type == "p")%>%
  mutate(bin = case_when(
    (p <0.01)~ 'p<0.01',
    (p>0.01 & p < 0.05)~ "0.01<p<0.05",
    (p>0.05)~"p>0.05"))
jan_b1b3_leafarea <- filter(jan_b1b3_plot, measurement == "leafarea", type == "p")%>%
  mutate(bin = case_when(
    (p <0.01)~ 'p<0.01',
    (p>0.01 & p < 0.05)~ "0.01<p<0.05",
    (p>0.05)~"p>0.05"))

```

In order to use these bins as the fill for the heat maps, we need to first convert them to a factor, reorder these factors so p<0.01 appears as the first bin, and reorder by number, so that wild type is first, followed by single mutants, followed by double mutants.

```{r jan_b1b3_modify_bins}

###In order to use these bins as the fill in a heat map, convert to a factor
jan_b1b3_phi2$bin <- as.factor(jan_b1b3_phi2$bin)
jan_b1b3_leafarea$bin <- as.factor(jan_b1b3_leafarea$bin)


###We want p<0.1 to be first in the legend, so refactor with p<0.01 as the first term
jan_b1b3_phi2$bin <- relevel(jan_b1b3_phi2$bin, 'p<0.01')
jan_b1b3_leafarea$bin <- relevel(jan_b1b3_leafarea$bin, 'p<0.01')

###Reorder by number so heat map has WT first, then single, then double mutants
jan_b1b3_phi2$genotype <- reorder(jan_b1b3_phi2$genotype, jan_b1b3_phi2$number)
jan_b1b3_leafarea$genotype <- reorder(jan_b1b3_leafarea$genotype, jan_b1b3_leafarea$number)

```


Next, create a heat map for each measurement. In each case:
* x is time point
* y is genotype
* fill is p-value

```{r jan_b1b3_uncorrected_p_value_heat_maps}

##### ----- Jan B1B3 p-value heat map - phi2 ------
ggplot(data = jan_b1b3_phi2, aes(x = time_point, y = genotype, fill = bin)) + 
  labs(fill = "P-Value, \nwithout FDR Correction", x = "Hours", y = NULL, title = "January: Phi2 P-value, Uncorrected, for B1B3")+
  geom_tile(width = 10 , height = 20)+
  facet_grid(genotype ~ day, scales = "free", switch = "y")+
  #scale_x_continuous(breaks = round(c(0,15,24,39.5,48,63.7,72,
  #87,96,112,120,135,144,
  #159,168,183,192,207,216,231,240,255,264,279),0))+
  theme_tufte(base_family = "Calibri",
              base_size = 50)+
  theme(strip.background.y = element_blank(),
        strip.text.y = element_blank(),
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.spacing=unit(0, "lines"))+
  scale_fill_manual(values = c("red", "orange", "black"))
#ggsave("jan_b1b3_phi2_uncorrected.png", scale = 4)

##### ----- Jan B1B3 p-value heat map - leafarea ------
ggplot(data = jan_b1b3_leafarea, aes(x = time_point, y = genotype, fill = bin)) + 
  labs(fill = "P-Value, \nwithout FDR Correction", x = "Hours", y = NULL, title = "January: Leafarea P-value, Uncorrected, for B1B3")+
  geom_tile(width = 10 , height = 20)+
  facet_grid(genotype ~ day, scales = "free", switch = "y")+
  #scale_x_continuous(breaks = round(c(0,15,24,39.5,48,63.7,72,
  #87,96,112,120,135,144,
  #159,168,183,192,207,216,231,240,255,264,279),0))+
  theme_tufte(base_family = "Calibri",
              base_size = 50)+
  theme(strip.background.y = element_blank(),
        strip.text.y = element_blank(),
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.spacing=unit(0, "lines"))+
  scale_fill_manual(values = c("red", "orange", "black"))
#ggsave("jan_b1b3_leafarea_uncorrected.png", scale = 4)
```

### Corrected p-value heat maps

Now, we want these same visualizations but using the corrected p-values instead of uncorrected p-values. Once again, leaf area is not significant, so no need to include a heat map of p-values. 

```{r jan_b1b3_plot_data_adj}
###Create seperate data frames for each measurement to use in heat maps; only use adjusted p-values
jan_b1b3_phi2_adj <- filter(jan_b1b3_plot, measurement == "phi2", type == "p_adj")%>%
  ###Create a new column with the p-value "bins"
  mutate(bin = case_when(
    (p <0.05)~ 'p<0.05',
    (p>0.05)~"p>0.05"))
jan_b1b3_leafarea_adj <- filter(jan_b1b3_plot, measurement == "leafarea", type == "p_adj")%>%
  ###Create a new column with the p-value "bins"
  mutate(bin = case_when(
    (p <0.01)~ 'p<0.01',
    (p>0.01 & p < 0.05)~ "0.01<p<0.05",
    (p>0.05)~"p>0.05"))
```

Modify the bins and properly sort the bins and genotypes for the p-value heat maps.

```{r jan_b1b3_plot_modify_bins_adj}
###In order to use these bins as the fill in a heat map, convert to a factor
jan_b1b3_phi2_adj$bin <- as.factor(jan_b1b3_phi2_adj$bin)
jan_b1b3_leafarea_adj$bin <- as.factor(jan_b1b3_leafarea_adj$bin)

###We want p<0.1 to be first in the legend, so refactor with p<0.01 as the first term
#The minimum p value for phi2 is above 0.01, so we only have two factors - less than or greater than 0.05
jan_b1b3_phi2_adj$bin <- relevel(jan_b1b3_phi2_adj$bin, 'p<0.05')
jan_b1b3_leafarea_adj$bin <- relevel(jan_b1b3_leafarea_adj$bin, 'p<0.01')

###Reorder by number so heat map has WT first, then single, then double mutants
jan_b1b3_phi2_adj$genotype <- reorder(jan_b1b3_phi2_adj$genotype, jan_b1b3_phi2_adj$number)
jan_b1b3_leafarea_adj$genotype <- reorder(jan_b1b3_leafarea_adj$genotype, jan_b1b3_leafarea_adj$number)


```


```{r}
jan_b1b3_plot%>%filter(type == "p_adj")%>%group_by(measurement)%>%summarize(sum(p<0.01), sum(p>0.01 & p<0.05))
```

This does not have the same pattern we saw with the December and February data sets. There are a large number of significant p-values for leaf area, whereas we saw none in December and February. This needs to be investigated. 

Create heat maps for the adjusted p-values.

```{r jan_p_value_heat_maps_adj}

##### ----- Jan B1B3 p-value heat map - phi2 ------
ggplot(data = jan_b1b3_phi2_adj, aes(x = time_point, y = genotype, fill = bin)) + 
  labs(fill = "P-Value, \nwith FDR Correction", x = "Hours", y = NULL, title = "January: Phi2 P-value, Corrected, for B1B3")+
  geom_tile(width = 10 , height = 20)+
  facet_grid(genotype ~ day, scales = "free", switch = "y")+
  #scale_x_continuous(breaks = round(c(0,15,24,39.5,48,63.7,72,
  #87,96,112,120,135,144,
  #159,168,183,192,207,216,231,240,255,264,279),0))+
  theme_tufte(base_family = "Calibri",
              base_size = 50)+
  theme(strip.background.y = element_blank(),
        strip.text.y = element_blank(),
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.spacing=unit(0, "lines"))+
  scale_fill_manual(values = c("red", "black"))
#ggsave("jan_b1b3_phi2_corrected.png", scale = 4)

##### ----- Jan B1B3 p-value heat map - phi2 ------
ggplot(data = jan_b1b3_leafarea_adj, aes(x = time_point, y = genotype, fill = bin)) + 
  labs(fill = "P-Value, \nwith FDR Correction", x = "Hours", y = NULL, title = "January: Leafarea P-value, Corrected, for B1B3")+
  geom_tile(width = 10 , height = 20)+
  facet_grid(genotype ~ day, scales = "free", switch = "y")+
  #scale_x_continuous(breaks = round(c(0,15,24,39.5,48,63.7,72,
  #87,96,112,120,135,144,
  #159,168,183,192,207,216,231,240,255,264,279),0))+
  theme_tufte(base_family = "Calibri",
              base_size = 50)+
  theme(strip.background.y = element_blank(),
        strip.text.y = element_blank(),
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.spacing=unit(0, "lines"))+
  scale_fill_manual(values = c("red", "orange", "black"))
#ggsave("jan_b1b3_phi2_corrected.png", scale = 4)
```


## Cell 371
Next, we'll transition to general visualizations for January for the B1B3 genotypes. 

Apply the cell_371_data function to the B1B3 January subset, and add columns with the day, number, and number_2.

```{r jan_cell_371}
cell_371_jan_b1b3 <- cell_371_data(add_day_col(jan_b1b3))

cell_371_jan_b1b3$genotype <- as.character(cell_371_jan_b1b3$genotype)
cell_371_jan_b1b3 <- add_number(cell_371_jan_b1b3)


#cell_371_jan_b1b3$day <- as.integer(cell_371_jan_b1b3$day)

cell_371_jan_b1b3 <- cell_371_jan_b1b3%>%arrange(day)
```

Next, we want to verify that our function is giving us the correct log fold values.

```{r jan_verify_median}
###Test 1 
a <- filter(jan_b1b3, genotype == "b1b3", time_point == "1", measurement == "npq")$measured_value
b <- filter(jan_b1b3, genotype == "Col0", time_point == "1", measurement == "npq")$measured_value
c <- log2(median(a/median(b)))
unique(c)
unique(filter(cell_371_jan_b1b3, genotype == "b1b3", time_point == "1", measurement == "npq")$log2_fold)
###Test 2 
d <- filter(jan_b1b3, genotype == "b1", time_point == "1", measurement == "phi2")$measured_value
e <- filter(jan_b1b3, genotype == "Col0", time_point == "1", measurement == "phi2")$measured_value
f <- log2(median(d/median(e)))
f
unique(filter(cell_371_jan_b1b3, genotype == "b1", time_point == "1", measurement == "phi2")$log2)

```


Everything looks good - time to plot!

Begin by creating heat maps using the data from the Cell 371 preperation. Create subsets of the December data based on measurement, and reorder each of the subsets by the number. 

```{r dec_cell_371_subsets}
cell_371_leafarea_jan_b1b3 <- cell_371_jan_b1b3%>%filter(measurement == "leafarea")%>%arrange(number_2,day)
cell_371_npq_jan_b1b3 <- cell_371_jan_b1b3%>%filter(measurement == "npq")%>%arrange(number_2,day)
cell_371_phi2_jan_b1b3<- cell_371_jan_b1b3%>%filter(measurement == "phi2")%>%arrange(number_2,day)

###Reorder each measurement data set by the number column so Col0 is on top, followed by single, followed by double mutants
cell_371_leafarea_jan_b1b3$genotype <- reorder(cell_371_leafarea_jan_b1b3$genotype, cell_371_leafarea_jan_b1b3$number_2)
cell_371_npq_jan_b1b3$genotype <- reorder(cell_371_npq_jan_b1b3$genotype, cell_371_npq_jan_b1b3$number_2)
cell_371_phi2_jan_b1b3$genotype <- reorder(cell_371_phi2_jan_b1b3$genotype, cell_371_phi2_jan_b1b3$number_2)

```

```{r jan_b1b3_logfold_summary}
summary(cell_371_jan_b1b3$log2_fold)
```

Next, plot the data. Some notes: I chose to set the color scale to be in the range of -0.65 to 0.4 for all measurements. I chose the same scale so that all three heat maps were comparable. This encompasses the range of the log fold change values for December. 

```{r jan_b1b3_logfold_heat_maps}
##### ----- Jan B1B3 Phi2 heat map - all genotypes ------

ggplot(data = filter(cell_371_phi2_jan_b1b3, genotype != "Col0"), aes(x = time_point, y = genotype, fill = log2_fold)) + 
  labs(fill = "Log 2 Fold Change", x = "Hours", y = NULL, title = "January: Phi2 Log 2 Fold Change, for B1B3")+
  #geom_tile(width = 10 , height = 20)+
  geom_tile(width = 10, height = 10)+
  facet_grid(genotype ~ day, scales = "free", switch = "y")+
  #scale_x_continuous(breaks = round(c(0,15,24,39.5,48,63.7,72,
  #87,96,112,120,135,144,
  #159,168,183,192,207,216,231,240,255,264,279),0))+
  theme_tufte(base_family = "Calibri",
               base_size = 50)+
  # theme(strip.background.y = element_blank(),
  #       strip.text.y = element_blank(),
  #       panel.spacing=unit(0, "lines"))+
  # 
  theme(strip.background.y = element_blank(),
        strip.text.y = element_blank(),
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.spacing=unit(0, "lines"))+
  #scale_fill_manual(values = )
  scale_fill_gradient2(low = "blue", high="red", mid = "white", midpoint = 0, limits = c(-0.65, 0.4), breaks = c(-0.65, 0, 0.4), labels = c("-0.65", "0", "0.4"))
#ggsave("jan_b1b3_phi2_heatmap.png", scale = 4)

##### ----- Jan B1B3 Leaf area heat map - all genotypes ------

###Confirm that each day has two "cells" - this is because we selected only start and end points for each day
ggplot(data = filter(cell_371_leafarea_jan_b1b3, genotype != "Col0"), aes(x = time_point, y = genotype, fill = log2_fold)) + 
  labs(fill = "Log 2 Fold Change", x = "Hours", y = NULL, title = "January: Leaf Area Log 2 Fold Change, for B1B3")+
  geom_tile(width = 16 , height = 30)+
  facet_grid(genotype ~ day, scales = "free", switch = "y")+
  #scale_x_continuous(breaks = round(c(0,15,24,39.5,48,63.7,72,
  #87,96,112,120,135,144,
  #159,168,183,192,207,216,231,240,255,264,279),0))+
  theme_tufte(base_family = "Calibri",
              base_size = 50)+
  # theme(strip.background.y = element_blank(),
  #       strip.text.y = element_blank(),
  #       panel.spacing=unit(0, "lines"))+
  theme(strip.background.y = element_blank(),
        strip.text.y = element_blank(),
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.spacing=unit(0, "lines"))+
  scale_fill_gradient2(low = "blue", high="red", mid = "white", midpoint = 0, limits = c(-0.65, 0.4), breaks = c(-0.65, 0, 0.4), labels = c("-0.65", "0", "0.4"))
#ggsave("jan_b1b3_leafarea_heatmap.png", scale = 4)

##### ----- Jan B1B3 NPQ heat map - all genotypes ------

ggplot(data = filter(cell_371_npq_jan_b1b3, genotype != "Col0"), aes(x = time_point, y = genotype, fill = log2_fold)) + 
  labs(fill = "Log 2 Fold Change", x = "Hours", y = NULL, title = "January: NPQ Log 2 Fold Change, for B1B3")+
  geom_tile(width = 10 , height = 20)+
  facet_grid(genotype ~ day, scales = "free", switch = "y")+
  #scale_x_continuous(breaks = round(c(0,15,24,39.5,48,63.7,72,
  #87,96,112,120,135,144,
  #159,168,183,192,207,216,231,240,255,264,279),0))+
  theme_tufte(base_family = "Calibri",
              base_size = 50)+
  # theme(strip.background.y = element_blank(),
  #       strip.text.y = element_blank(),
  #       panel.spacing=unit(0, "lines"))+
  
  theme(strip.background.y = element_blank(),
        strip.text.y = element_blank(),
        axis.title.x=element_blank(),
        axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        panel.spacing=unit(0, "lines"))+
  scale_fill_gradient2(low = "blue", high="red", mid = "white", midpoint = 0, limits = c(-0.65, 0.4), breaks = c(-0.65, 0, 0.4), labels = c("-0.65", "0", "0.4"))
#ggsave("jan_b1b3_npq_heatmap.png", scale = 4)

```

Here, we excluded the loop that created the heatmaps of genotype combinations for the mpk genotypes. There is no need, because we are only comparing three genotypes. 

## Cell 370
Now that we've plotted the heat maps, we can move forward with plots mirrored after page 370 in the Cell paper.

Apply the cell_370_data_function to the January data, and add columns with the day, number, and number_2.

Note that this data is prepared  bit differently from other experiments. This is because when I initially plotted the data, the days were not arranged in numeric order, but rather 1, 10, 11, 12, 2...

So, there is additional code here that converts the day to an integer. This solved the problem of order.

```{r jan_b1b3_cell_370}
###Apply the cell_370_data function to the jan_b1b3 data
cell_370_data_jan_b1b3 <- cell_370_data(jan_b1b3)
###Add a column with the day to the data
cell_370_data_jan_b1b3 <- add_day_col(cell_370_data_jan_b1b3)
###Add columns with number and number_2 - we will use these to sort the genotypes in the plot
cell_370_data_jan_b1b3 <- add_number(cell_370_data_jan_b1b3)
###Convert the genotype to a character - right now it is an integer for some reason - so we can arrange the genotypes
cell_370_data_jan_b1b3$genotype <- as.character(cell_370_data_jan_b1b3$genotype)
###Reorder the genotypes so the double mutant is in between the two single mutants in the scale
cell_370_data_jan_b1b3$genotype <- reorder(cell_370_data_jan_b1b3$genotype, cell_370_data_jan_b1b3$number)
###Convert the day to an integer so we can sort by the day
#cell_370_data_jan_b1b3$day <- as.integer(cell_370_data_jan_b1b3$day)
```

Here, we excluded the loop that created the heatmaps for the mpk genotypes. There is no need, because we are only comparing three genotypes. 

```{r jan_b1b3_cell_370_plots}
ggplot(data = cell_370_data_jan_b1b3, aes(x = time_point, y = med))+
    geom_line(aes(color = genotype), size = 4)+
    facet_rep_grid(measurement ~ day, scales = "free" , switch = "y", repeat.tick.labels = FALSE)+
    labs(x = "Hours", y = NULL)+
    theme_tufte(base_family = "Calibri",
                base_size = 50)+
    theme(strip.background.x = element_blank(),
          panel.border = element_rect(color = "black", fill = NA, size = 1),
          axis.line=element_line(),
          panel.spacing = unit(1, "lines"),
          axis.title.x=element_blank(),
          axis.text.x=element_blank(),
          axis.ticks.x=element_blank())+
    scale_color_viridis_d(begin = 0, end = 1, option = 'viridis', aesthetics = c("colour", "fill"))
#ggsave("jan_b1b3_median_plot.png", scale = 4)
```

